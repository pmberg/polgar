<!DOCTYPE html>
<html>
  <head>
    <title>The POLGAR Project</title>
    <link rel="stylesheet" href="styles.css" />
  </head>

  <body>
    <h1>The POLGAR Project</h1>
    <p>
      A website about practically oriented learning for general alignment
      research, across a wide range of areas. Here is an
      <a href="trialindex.html">experimental link to a new homepage</a>
    </p>

    <div class="section">
      <h2 class="core">Core</h2>
      <p>
        Core material is focused on basic technical content useful for all sorts
        of professionals, as well as core AI safety content useful for all
        different applications.
      </p>
    </div>

    <div class="section">
      <h2 class="technical">Technical Alignment</h2>
      <p>
        Technical Alignment content is content that is useful in both
        theoretical and engineering applications, but may not be as useful in
        policy/governance. However, it is more likely to come in handy in a
        policy/governance context than Theoretical or Engineering content is.
      </p>
    </div>

    <div class="section">
      <h2 class="engineering">Engineering</h2>
      <p>
        Engineering content is focused on practical implementation of AI safety
        mechanisms, including technical safeguards, testing methodologies, and
        robustness measures.
      </p>
    </div>

    <div class="section">
      <h2 class="theoretical">Theoretical</h2>
      <p>
        Theoretical content is focused on theoretical alignment research,
        focused more on resolving unsolved fundamental problems in the MLAI
        space than on developing alignment technologies for current systems.
      </p>
    </div>

    <div class="section">
      <h2 class="governance">Governance</h2>
      <p>
        Governance content addresses policy frameworks, institutional design,
        and coordination mechanisms for ensuring safe and beneficial AI
        development.
      </p>
    </div>
  </body>
</html>
